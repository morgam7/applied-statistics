{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32b6ee64",
   "metadata": {},
   "source": [
    "# Springboard Data Analytics Assignment\n",
    "\n",
    "**Author:** Marcella Morgan\n",
    "**Image Credit:** Images generated with the help of ChatGPT (OpenAI).\n",
    "![Lady tasting tea + normal curve](images/lady_drinking_tea.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ad47f2",
   "metadata": {},
   "source": [
    "## Introduction  \n",
    "\n",
    "In this assignment I’m working through four problems that all use simulation to explore different ideas in statistics.  \n",
    "\n",
    "1. **Lady Tasting Tea (Extended):**  \n",
    "   I’ll extend the classic experiment to 12 cups instead of 8, simulate the chance of guessing correctly, and compare the results to the original setup.  \n",
    "\n",
    "2. **Normal Distribution:**  \n",
    "   I’ll generate lots of small samples from a normal distribution and compare the sample standard deviation (ddof=1) with the population version (ddof=0). The goal is to see the difference on histograms and think about what happens with bigger samples.  \n",
    "\n",
    "3. **t-Tests and Type II Errors:**  \n",
    "   Here I’ll run simulations of t-tests while changing the difference in means. I’ll measure how often the test fails to reject the null when it should (type II errors) and see how that changes as the effect gets stronger.  \n",
    "\n",
    "4. **ANOVA vs t-Tests:**  \n",
    "   I’ll generate three groups with different means and compare running one ANOVA versus doing three separate t-tests. The point is to see why ANOVA is better when looking at more than two groups.  \n",
    "\n",
    "Overall, the assignment is about practicing simulation, interpreting results, and understanding why we choose one statistical test over another.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540aa6a0",
   "metadata": {},
   "source": [
    "## Problem 1: Lady Testing Tea"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e00aea3",
   "metadata": {},
   "source": [
    "In this section, we replicate and extend the classic Lady Tasting Tea experiment. The original design had 8 cups (4 tea-first, 4 milk-first). By chance, the probability of guessing correctly was small but non-negligible. Here, we increase the challenge by preparing 12 cups (8 tea-first and 4 milk-first). We simulate this setup repeatedly by shuffling the cups, recording how often the participant could identify all cups correctly purely by guessing. We then compare the estimated probability with the original experiment, interpret its implications for statistical power, and reflect on whether one might reasonably tighten or relax the significance threshold (p-value) when moving from the original 8-cup design to this 12-cup version.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e4f9f2",
   "metadata": {},
   "source": [
    "### Running the experiment\n",
    "\n",
    "We'll start by running the experiment with 8 cups tea-first and 4 cups milk first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2fbb952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import itertools\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Number of cups of tea in total.\n",
    "no_cups = 8\n",
    "\n",
    "# Number of cups of tea with milk in first.\n",
    "no_cups_milk_first = 4\n",
    "\n",
    "# Number of cups of tea with tea in first.\n",
    "no_cups_tea_first = 4\n",
    "\n",
    "# Number of ways of selecting four cups from eight.\n",
    "ways = math.comb(no_cups, no_cups_milk_first)\n",
    "\n",
    "# Show.\n",
    "ways"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb86ed80",
   "metadata": {},
   "source": [
    "So the lady has a 1 in 70 chance of randomly choosing the milk first teas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5002767f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "495"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of cups of tea in total.\n",
    "no_cups = 12\n",
    "\n",
    "# Number of cups of tea with milk in first.\n",
    "no_cups_milk_first = 8\n",
    "\n",
    "# Number of cups of tea with tea in first.\n",
    "no_cups_tea_first = 4\n",
    "\n",
    "# Number of ways of selecting four cups from eight.\n",
    "ways = math.comb(no_cups, no_cups_milk_first)\n",
    "\n",
    "# Show.\n",
    "ways"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70280d91",
   "metadata": {},
   "source": [
    "So the lady has a 1 in 495 chance of selecting the milk first tea by chance - so likely with this experiment she can tell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa3b468",
   "metadata": {},
   "source": [
    "## Problem 2: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cdf2c2",
   "metadata": {},
   "source": [
    "This task demonstrates the distinction between sample standard deviation (unbiased estimator) and population standard deviation (biased but lower variance). We generate a very large number of small samples (100,000 samples of size 10) from a standard normal distribution. For each, we calculate the standard deviation using two different definitions:\n",
    "\n",
    "ddof=0: divides by n, appropriate for a full population.\n",
    "\n",
    "ddof=1: divides by n-1, correcting bias when estimating from a sample.\n",
    "\n",
    "We then plot histograms of these results on the same axes, using transparency to highlight differences. The visualization should reveal a small but systematic shift between the two. We conclude by discussing how increasing the sample size would shrink this difference, illustrating the consistency of estimators."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f45aab6",
   "metadata": {},
   "source": [
    "## Problem 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ce501b",
   "metadata": {},
   "source": [
    "In this section, we investigate type II errors, which occur when a test fails to reject the null hypothesis despite there being a true difference. We systematically vary the mean difference (d) between two normal distributions, from 0 to 1.0 in steps of 0.1. For each value of d:\n",
    "\n",
    "Draw two samples of size 100 (one from N(0,1), the other from N(d,1)).\n",
    "\n",
    "Perform an independent two-sample t-test, using a 5% significance level.\n",
    "\n",
    "Repeat the process 1,000 times and record the proportion of times the null hypothesis was not rejected.\n",
    "\n",
    "We then plot type II error rates against effect size, showing the classic trade-off: small differences are harder to detect, while large differences result in low type II error. This simulation reinforces the importance of effect size and sample size in determining test power."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17591dd1",
   "metadata": {},
   "source": [
    "## Problem 4:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67211b32",
   "metadata": {},
   "source": [
    "In this task, we simulate a classic comparison of statistical approaches for multiple group testing. We generate three independent samples (each size 30) from normal distributions with means 0, 0.5, and 1 (standard deviation fixed at 1). Two approaches are then applied:\n",
    "\n",
    "One-way ANOVA: tests the null hypothesis that all three group means are equal in a single, global test.\n",
    "\n",
    "Multiple independent t-tests: three pairwise comparisons (1 vs 2, 1 vs 3, 2 vs 3).\n",
    "\n",
    "We compare the results and discuss why ANOVA is typically preferred: it provides a unified test that controls type I error across multiple comparisons. Running several t-tests increases the risk of false positives (familywise error rate), making ANOVA more robust and interpretable for multi-group scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ba624b",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
